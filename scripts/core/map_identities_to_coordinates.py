#!/usr/bin/env python3
"""
Mappe alle gefundenen Identities zu ihren Matrix-Koordinaten.

Analysiert die rÃ¤umliche Verteilung der Identities in der Matrix.
"""

import json
import numpy as np
from pathlib import Path
from collections import defaultdict, Counter
from typing import List, Dict, Tuple

OUTPUT_DIR = Path("outputs/derived")
REPORTS_DIR = Path("outputs/reports")

def load_anna_matrix():
 """Load Anna Matrix."""
 from analysis.utils.data_loader import load_anna_matrix
 return load_anna_matrix()

def load_onchain_identities() -> List[str]:
 """Load alle on-chain Identities."""
 identities = []
 
 complete_file = OUTPUT_DIR / "checksum_identities_onchain_validation_complete.json"
 if complete_file.exists():
 with complete_file.open() as f:
 complete_data = json.load(f)
 total_batches = complete_data.get("total_batches", 0)
 
 for i in range(total_batches):
 batch_file = OUTPUT_DIR / f"onchain_identities_batch_{i}.json"
 if batch_file.exists():
 with batch_file.open() as f:
 batch_data = json.load(f)
 if isinstance(batch_data, list):
 identities.extend(batch_data)
 
 return identities

def find_identity_coordinates(matrix: np.ndarray, identity: str) -> List[Tuple[int, int]]:
 """Finde alle Koordinaten wo diese Identity gefunden wurde."""
 # Vereinfachte Suche - in echt mÃ¼sste man die Extraction-Methoden nachvollziehen
 # FÃ¼r jetzt: Suche nach Base-26 encoded patterns
 coordinates = []
 
 # TODO: Implementiere echte Koordinaten-Suche basierend auf Extraction-Methoden
 # FÃ¼r jetzt: Placeholder
 
 return coordinates

def analyze_spatial_distribution(coordinates: List[Tuple[int, int]], matrix_size: Tuple[int, int]) -> Dict:
 """Analyze rÃ¤umliche Verteilung."""
 
 if not coordinates:
 return {}
 
 # Konvertiere zu numpy array
 coords_array = np.array(coordinates)
 
 # Analyze Verteilung
 x_coords = coords_array[:, 0]
 y_coords = coords_array[:, 1]
 
 analysis = {
 "total_coordinates": len(coordinates),
 "x_distribution": {
 "min": int(x_coords.min()),
 "max": int(x_coords.max()),
 "mean": float(x_coords.mean()),
 "std": float(x_coords.std()),
 },
 "y_distribution": {
 "min": int(y_coords.min()),
 "max": int(y_coords.max()),
 "mean": float(y_coords.mean()),
 "std": float(y_coords.std()),
 },
 "density": {
 "total_cells": matrix_size[0] * matrix_size[1],
 "occupied_cells": len(set(coordinates)),
 "density": len(set(coordinates)) / (matrix_size[0] * matrix_size[1]) * 100,
 },
 }
 
 return analysis

def main():
 """Hauptfunktion."""
 
 print("=" * 80)
 print("MAP IDENTITIES TO COORDINATES")
 print("=" * 80)
 print()
 
 print("Loading Anna Matrix...")
 matrix = load_anna_matrix()
 print(f"âœ… Matrix loaded: {matrix.shape}")
 print()
 
 print("Loading on-chain identities...")
 identities = load_onchain_identities()
 print(f"âœ… {len(identities):,} identities loaded")
 print()
 
 print("Mapping identities to coordinates...")
 print("(This requires implementing coordinate search based on extraction methods)")
 print()
 
 # TODO: Implementiere echte Koordinaten-Mapping
 # FÃ¼r jetzt: Placeholder-Analyse
 
 print("=" * 80)
 print("NOTE: Coordinate mapping requires implementation")
 print("=" * 80)
 print()
 print("To implement:")
 print("1. Track coordinates during identity extraction")
 print("2. Store coordinate-identity mapping")
 print("3. Analyze spatial patterns")
 print()
 
 # Speichere Placeholder
 OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 json_file = OUTPUT_DIR / "identity_coordinate_mapping.json"
 with json_file.open("w") as f:
 json.dump({
 "note": "Coordinate mapping requires implementation",
 "total_identities": len(identities),
 "matrix_size": matrix.shape,
 }, f, indent=2)
 
 print(f"ðŸ’¾ Placeholder saved to: {json_file}")

if __name__ == "__main__":
 main()

