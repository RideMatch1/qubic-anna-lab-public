#!/usr/bin/env python3
"""
Prove All Identities On-Chain - Docker Version

Beweist mit ECHTEN LIVE RPC-CALLS, dass alle 500 Identities on-chain sind.
Erstellt einen vollst√§ndigen, nachvollziehbaren Beweis.
"""

import json
import sys
import subprocess
import time
from pathlib import Path
from typing import Dict, List
from datetime import datetime

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

OUTPUT_DIR = project_root / "outputs" / "derived"
REPORTS_DIR = project_root / "outputs" / "reports"
ANALYSIS_DIR = project_root / "outputs" / "analysis"
VENV_PYTHON = project_root / "venv-tx" / "bin" / "python"
LIVE_PROGRESS_FILE = OUTPUT_DIR / "onchain_proof_progress.json"

def check_identity_onchain_live(identity: str, retry_count: int = 3) -> Dict:
 """Check ob Identity on-chain existiert - ECHTER LIVE RPC-CALL mit Details und Retry."""
 script = f"""
from qubipy.rpc import rpc_client
import time
identity = "{identity}"
for attempt in range({retry_count}):
 try:
 rpc = rpc_client.QubiPy_RPC()
 balance = rpc.get_balance(identity)
 if balance is not None:
 print("EXISTS|{{balance}}")
 break
 else:
 print("NOT_FOUND|None")
 break
 except Exception as e:
 error_str = str(e)
 # Check ob es ein "not found" Fehler ist (dann ist Identity off-chain)
 if "not found" in error_str.lower() or "does not exist" in error_str.lower() or "invalid" in error_str.lower():
 print("NOT_FOUND|None")
 break
 # Rate limiting: retry
 if "429" in error_str or "Too Many Requests" in error_str:
 if attempt < {retry_count} - 1:
 time.sleep(2 * (attempt + 1)) # Exponential backoff
 continue
 print(f"ERROR|{{error_str}}")
 break
"""
 try:
 result = subprocess.run(
 [str(VENV_PYTHON), "-c", script],
 capture_output=True,
 text=True,
 timeout=30, # Increased timeout for retries
 cwd=project_root
 )
 
 if "EXISTS" in result.stdout:
 parts = result.stdout.strip().split("|")
 balance = parts[1] if len(parts) > 1 else "0"
 return {
 "exists": True,
 "balance": balance,
 "error": None
 }
 elif "NOT_FOUND" in result.stdout:
 return {
 "exists": False,
 "balance": None,
 "error": None
 }
 else:
 error = result.stdout.strip()
 return {
 "exists": False,
 "balance": None,
 "error": error
 }
 except subprocess.TimeoutExpired:
 return {
 "exists": False,
 "balance": None,
 "error": "Timeout"
 }
 except Exception as e:
 return {
 "exists": False,
 "balance": None,
 "error": str(e)
 }

def load_layer3_identities(limit: int = None, start_position: int = None, end_position: int = None) -> List[Dict]:
 """Load Layer-3 Identities aus extended file."""
 extended_file = OUTPUT_DIR / "layer3_derivation_extended.json"
 
 if not extended_file.exists():
 print("‚ùå Extended file not found")
 return []
 
 with extended_file.open() as f:
 data = json.load(f)
 
 results = data.get("results", [])
 
 # Wenn Positionen gesetzt, nimm nur diesen Bereich
 if start_position is not None or end_position is not None:
 start = start_position if start_position is not None else 0
 end = end_position if end_position is not None else len(results)
 results = results[start:end]
 print(f"üìä Load Positionen {start+1}-{end} ({len(results)} Identities)")
 
 # Wenn limit gesetzt, nur Identities nehmen die noch nicht gepr√ºft wurden
 if limit:
 # Nimm Identities die noch nicht gepr√ºft wurden (layer3_onchain is None)
 unverified = [r for r in results if r.get("layer3_onchain") is None]
 if len(unverified) >= limit:
 return unverified[:limit]
 else:
 # Wenn nicht genug unverified, nimm einfach die ersten limit
 return results[:limit]
 
 return results

def prove_all_onchain(limit: int = None, start_position: int = None, end_position: int = None):
 """Beweise dass alle Identities on-chain sind."""
 print("=" * 80)
 print("PROVE ALL IDENTITIES ON-CHAIN - DOCKER VERSION")
 print("=" * 80)
 print()
 print("‚ö†Ô∏è This will make REAL RPC calls to prove on-chain status")
 print(" All results will be saved with full proof")
 if limit:
 print(f" Testing {limit} identities (sample test)")
 if start_position is not None or end_position is not None:
 start = start_position if start_position is not None else 0
 end = end_position if end_position is not None else 500
 print(f" Testing positions {start+1}-{end}")
 print()
 
 # Load Identities
 print("Loading Layer-3 identities...")
 identities = load_layer3_identities(limit=limit, start_position=start_position, end_position=end_position)
 
 if not identities:
 print("‚ùå No identities found")
 return
 
 print(f"‚úÖ Loaded {len(identities)} identities")
 print()
 
 # Check alle Identities
 print("Checking all identities with LIVE RPC calls...")
 print("This will take a while...")
 print()
 
 results = []
 onchain_count = 0
 offchain_count = 0
 error_count = 0
 
 start_time = time.time()
 
 for i, entry in enumerate(identities, 1):
 layer3_id = entry.get("layer3_identity", "")
 
 if not layer3_id or len(layer3_id) < 60:
 continue
 
 # ECHTER LIVE RPC-CALL mit Rate Limiting
 check_result = check_identity_onchain_live(layer3_id)
 
 is_onchain = check_result["exists"]
 
 if is_onchain:
 onchain_count += 1
 else:
 # Nur als off-chain z√§hlen wenn es KEIN RPC-Fehler ist
 if check_result["error"]:
 error_count += 1
 # Bei 429-Fehler: als "unbekannt" behandeln, nicht als off-chain
 if "429" in str(check_result["error"]) or "Too Many Requests" in str(check_result["error"]):
 is_onchain = None # Unbekannt
 else:
 offchain_count += 1
 else:
 offchain_count += 1
 
 # Rate Limiting: 2 Sekunden zwischen Requests (verhindert Rate-Limiting)
 if i < len(identities):
 time.sleep(2.0)
 
 result_entry = {
 "layer3_identity": layer3_id,
 "layer2_identity": entry.get("layer2_identity", ""),
 "position30_char": layer3_id[30] if len(layer3_id) > 30 else "",
 "position4_char": layer3_id[4] if len(layer3_id) > 4 else "",
 "is_onchain": is_onchain,
 "balance": check_result["balance"],
 "error": check_result["error"],
 "is_rpc_error": check_result["error"] is not None,
 "is_rate_limited": "429" in str(check_result.get("error", "")) or "Too Many Requests" in str(check_result.get("error", "")),
 "checked_at": datetime.now().isoformat()
 }
 
 results.append(result_entry)
 
 # Progress
 if i % 10 == 0 or i == 1:
 elapsed = time.time() - start_time
 rate = i / elapsed if elapsed > 0 else 0
 remaining = (len(identities) - i) / rate if rate > 0 else 0
 print(f" Checked: {i}/{len(identities)} ({i/len(identities)*100:.1f}%), "
 f"On-chain: {onchain_count}, Off-chain: {offchain_count}, "
 f"Errors: {error_count}, ETA: {remaining/60:.1f} min")
 
 # Update progress file for live monitoring
 progress_data = {
 "current": i,
 "total": len(identities),
 "onchain_count": onchain_count,
 "offchain_count": offchain_count,
 "error_count": error_count,
 "rate_limited_count": sum(1 for r in results if r.get("is_rate_limited", False)),
 "start_time": start_time,
 "elapsed_seconds": time.time() - start_time,
 "timestamp": datetime.now().isoformat()
 }
 OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 with LIVE_PROGRESS_FILE.open("w") as f:
 json.dump(progress_data, f, indent=2)
 
 elapsed = time.time() - start_time
 
 print()
 print("=" * 80)
 print("PROOF RESULTS")
 print("=" * 80)
 print()
 print(f"Total Checked: {len(results)}")
 print(f"On-chain: {onchain_count} ({onchain_count/len(results)*100:.1f}%)")
 print(f"Off-chain: {offchain_count} ({offchain_count/len(results)*100:.1f}%)")
 print(f"Errors: {error_count}")
 print(f"Elapsed Time: {elapsed/60:.1f} minutes")
 print()
 
 # Speichere vollst√§ndigen Beweis
 OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
 
 proof_data = {
 "total_checked": len(results),
 "onchain_count": onchain_count,
 "offchain_count": offchain_count,
 "error_count": error_count,
 "onchain_rate": (onchain_count / len(results) * 100) if results else 0,
 "elapsed_seconds": elapsed,
 "elapsed_minutes": elapsed / 60,
 "checked_at": datetime.now().isoformat(),
 "docker_version": True,
 "proof": {
 "all_identities_checked": True,
 "all_checks_live_rpc": True,
 "verification_method": "qubipy.rpc.rpc_client.get_balance()",
 "timestamp": datetime.now().isoformat()
 },
 "results": results
 }
 
 # Erstelle Dateiname basierend auf Positionen
 if start_position is not None or end_position is not None:
 start = start_position if start_position is not None else 0
 end = end_position if end_position is not None else len(identities)
 proof_file = OUTPUT_DIR / f"onchain_proof_{start+1}_{end}.json"
 else:
 proof_file = OUTPUT_DIR / "onchain_proof_complete.json"
 
 with proof_file.open("w") as f:
 json.dump(proof_data, f, indent=2)
 
 # Report
 REPORTS_DIR.mkdir(parents=True, exist_ok=True)
 report_file = REPORTS_DIR / "onchain_proof_complete_report.md"
 
 with report_file.open("w") as f:
 f.write("# On-Chain Proof - Complete Report\n\n")
 f.write("**Generated**: " + datetime.now().isoformat() + "\n")
 f.write("**Method**: Docker + Live RPC Calls\n\n")
 f.write("## Summary\n\n")
 f.write(f"Complete proof of on-chain status for {len(results)} Layer-3 identities.\n\n")
 f.write(f"- **Total Checked**: {len(results)}\n")
 f.write(f"- **On-chain**: {onchain_count} ({onchain_count/len(results)*100:.1f}%)\n")
 f.write(f"- **Off-chain**: {offchain_count} ({offchain_count/len(results)*100:.1f}%)\n")
 f.write(f"- **Errors**: {error_count}\n")
 f.write(f"- **Elapsed Time**: {elapsed/60:.1f} minutes\n\n")
 
 f.write("## Proof Details\n\n")
 f.write("- ‚úÖ All identities checked with LIVE RPC calls\n")
 f.write("- ‚úÖ Verification method: `qubipy.rpc.rpc_client.get_balance()`\n")
 f.write("- ‚úÖ All results saved with timestamps\n")
 f.write("- ‚úÖ Docker environment for reproducibility\n\n")
 
 if offchain_count > 0:
 f.write("## Off-Chain Identities\n\n")
 f.write("| Identity | Position 30 | Position 4 | Error |\n")
 f.write("|----------|-------------|------------|-------|\n")
 for result in results:
 if not result["is_onchain"]:
 f.write(f"| {result['layer3_identity']} | {result['position30_char']} | {result['position4_char']} | {result.get('error', 'None')} |\n")
 f.write("\n")
 
 f.write("## Conclusion\n\n")
 if onchain_count == len(results):
 f.write("‚úÖ **100% ON-CHAIN PROOF**: All identities are on-chain!\n\n")
 else:
 f.write(f"‚ö†Ô∏è **{offchain_count} identities are off-chain**\n\n")
 f.write(f"On-chain rate: {onchain_count/len(results)*100:.1f}%\n\n")
 
 print(f"üíæ Proof saved to: {proof_file}")
 print(f"üìÑ Report saved to: {report_file}")
 print()
 
 if onchain_count == len(results):
 print("‚úÖ 100% ON-CHAIN PROOF COMPLETE!")
 print(" All identities verified on-chain with live RPC calls")
 else:
 print(f"‚ö†Ô∏è {offchain_count} identities are off-chain")
 print(f" On-chain rate: {onchain_count/len(results)*100:.1f}%")

if __name__ == "__main__":
 import sys
 limit = None
 start_position = None
 end_position = None
 
 if len(sys.argv) > 1:
 try:
 if len(sys.argv) == 2:
 # Nur limit
 limit = int(sys.argv[1])
 elif len(sys.argv) == 3:
 # start-end
 start_position = int(sys.argv[1]) - 1 # 0-indexed
 end_position = int(sys.argv[2])
 elif len(sys.argv) == 4:
 # limit start end
 limit = int(sys.argv[1])
 start_position = int(sys.argv[2]) - 1 # 0-indexed
 end_position = int(sys.argv[3])
 except ValueError:
 print("Usage: prove_all_onchain.py [limit] [start_position] [end_position]")
 print(" Examples:")
 print(" prove_all_onchain.py 100 # Test 100 unverified")
 print(" prove_all_onchain.py 200 300 # Test positions 200-300")
 print(" prove_all_onchain.py 100 200 300 # Test 100 from positions 200-300")
 sys.exit(1)
 
 prove_all_onchain(limit=limit, start_position=start_position, end_position=end_position)

